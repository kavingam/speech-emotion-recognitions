{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ecd4409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0517578e-05 -3.0517578e-05  0.0000000e+00 ...  4.4860840e-03\n",
      "  2.6550293e-03  4.2419434e-03] 22050\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# Load an audio file\n",
    "y, sr = librosa.load('output.wav')\n",
    "\n",
    "# Print the audio signal and sampling rate\n",
    "print(y, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64b7c6b-51b5-4cd3-8c7b-c4fc5efd09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading an Audio File \n",
    "# Load audio files in various formats like wav, mp3,etc.\n",
    "# librosa.load will load the audio file and return two objects.\n",
    "\n",
    "# 1. y : time series of the audio signal (a NumPy array)\n",
    "# 2. sr: sampling rate (number of samples per second)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f91fba-4fb3-4dea-b40f-630fab2bd242",
   "metadata": {},
   "source": [
    "# Visualizing the waveforma\n",
    "# plot the waveform of the audio signal using matplotlib\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93306d78-6bfd-4fcb-8061-e0a4d06dfb57",
   "metadata": {},
   "source": [
    "# Extracting features\n",
    "# Mel Spectrogram , Librosa can compute a Mel-scaled spectrogram, which is useful in audio anlysis (speech and music processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce17f27b-23db-4601-91f6-b69b38163973",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m S_dB \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(S, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Plot the Mel spectrogram\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     10\u001b[0m librosa\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mspecshow(S_dB, sr\u001b[38;5;241m=\u001b[39msr, x_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, y_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%+2.0f\u001b[39;00m\u001b[38;5;124m dB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Compute the Mel spectrogram\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "# Convert to decibel units (log scale)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Plot the Mel spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937f7a9-185d-4bfa-8522-5104b447d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load an example audio file\n",
    "y, sr = librosa.load(librosa.ex('trumpet'))  # Load a built-in example from librosa\n",
    "\n",
    "# Compute the Mel spectrogram\n",
    "S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "# Convert the Mel spectrogram to decibel units (log scale)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Plot the Mel spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel-frequency spectrogram (dB)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929dfd6-9981-4730-b434-b4548277b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Features\n",
    "# Chroma features represent the 12 different pitch classes in an audio signal\n",
    "# use in tasks like musical key detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1dbd88-ebac-4c74-81a1-019aa2e39229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute chroma features\n",
    "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "# Plot the chroma feature\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', sr=sr)\n",
    "plt.colorbar()\n",
    "plt.title('Chroma feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4aaf0-e702-480c-abec-1ab2dfcf6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Crossing Rate\n",
    "# This feature counts the rate at which the signal changes its sign. it is useful for identifying tonal or percussive elements in the audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7c7ff-3038-4a44-8432-1927abf0db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the zero-crossing rate\n",
    "zcr = librosa.feature.zero_crossing_rate(y)\n",
    "\n",
    "# Print the mean zero-crossing rate\n",
    "print(f'Mean zero-crossing rate: {zcr.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c9513-8499-4d55-ab23-83452a711e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other common Features\n",
    "# MFCC (Mel-frequency cepstral coefficients) used for audio and speech feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadef3c0-3db8-4985-b11e-9ce768484206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "# Plot MFCCs\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595e1d3-dd82-4262-8e05-b33811c4a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving audio \n",
    "# To save the processed audio or modified signal, soundfile \n",
    "import soundfile as sf\n",
    "# Save the audio data to a new file\n",
    "sf.write('output.wav',y,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dedae8-b6f0-4a3e-ba59-1a4e93864556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitch and Tempo Manipulation\n",
    "# Change pitch : Shif the pitch of an audio signal by a number of semitones\n",
    "y_shifted = librosa.effects.pitch_shift(y, sr, n_steps=4)  # Shift up by 4 semitones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996b49d-7024-4e6d-8087-29f630584e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change tempo : Speed up or slow down the audio\n",
    "y_fast = librosa.effects.time_stretch(y, rate=1.5)  # Speed up by 50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f2d52-8c40-4127-90e3-8e5c7b919454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Librosa use \n",
    "# Music analysis : Beat tracking, key detection, and genre classification.\n",
    "# Speech processing : Speaker identification, emotion recognition, and speech-to-text\n",
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552ca90-e5e6-4629-bba8-40459b8db729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an audio file\n",
    "y, sr = librosa.load(librosa.ex('trumpet'))  # Example audio\n",
    "\n",
    "# Plot the waveform (audio signal)\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(y, sr=sr)\n",
    "plt.title('Waveform of the Audio Signal')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58df8b-a5e2-4c22-9e09-48b6a5b8ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to show audio signal \n",
    "# 1.librosa.load : Loads the audio file and return two object:\n",
    "# y: the audio time-series (sample)\n",
    "# sr: the sample rate of the audio\n",
    "\n",
    "# 2. librosa.display.waveshow: used to visualize the waveform of the audio signal\n",
    "# 3. plt.show() : Displays the plot of the waveform\n",
    "\n",
    "# Example waveform\n",
    "# X-axis : Represnts time in seconds\n",
    "# Y-axis : Represents amplitude (The loudness of the sound at any given point in time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805ff39-394a-4a39-b80e-125c85d2134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Replace 'path_to_your_audio_file.wav' with the actual file path\n",
    "audio_file_path = 'output.wav'\n",
    "\n",
    "# Load the audio file\n",
    "y, sr = librosa.load(audio_file_path)\n",
    "\n",
    "# Save the audio signal (y) to a text file\n",
    "np.savetxt('sound_signal.txt', y)\n",
    "\n",
    "print(f\"Audio signal from {audio_file_path} saved to 'audio_signal.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737f99f-18fd-4c9a-92e7-cc9b677b90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own audio file and save the audio signal to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c7c71-6752-4027-95cf-2b6d831c0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Load an audio file\n",
    "y, sr = librosa.load(librosa.ex('trumpet'))  # Example audio\n",
    "\n",
    "# Save the audio signal (y) to a text file\n",
    "np.savetxt('audio_signal.txt', y)\n",
    "\n",
    "print(\"Audio signal saved to 'audio_signal.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c3771-9a2e-42aa-9862-fdca504af60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Audio Signal to a Text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4890c-9b70-43dc-8001-5f6153b7f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Audio Signal from a text file and Visualize it\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the audio signal from the text file\n",
    "y_loaded = np.loadtxt('audio_signal.txt')\n",
    "\n",
    "# Print the first few samples of the loaded signal\n",
    "print(\"Loaded audio signal samples:\", y_loaded[:10])  # Print first 10 samples\n",
    "\n",
    "# Plot the waveform of the loaded audio signal\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_loaded)\n",
    "plt.title('Waveform of the Loaded Audio Signal')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad875b-4a89-455c-811c-1cffb505af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sample rate and calculate the number of samples\n",
    "# The default number of samples in an signal depends on various factors, including, the duration of the audio and the sample rate at which it was recorded or played back.\n",
    "# the default number of samples in an audio signal\n",
    "\n",
    "# determining the number of ssamples \n",
    "# sample rate (sr) : this is the number of sample per seconds. common sample rates include\n",
    "# 44,100 HZ (CD quality)\\\n",
    "# 22,050 Hz\n",
    "# 16, 00 Hz (common in speech procssing)\n",
    "# 48.000 Hz (common in video production)\n",
    "\n",
    "# Duration : the total length of the audio in seconds\n",
    "\n",
    "# Formula to calculate the total number of samples in an audio signal total sample = sample rate * duration\n",
    "\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "y, sr = librosa.load('output.wav')  # Replace with your file path\n",
    "\n",
    "# Calculate the number of samples\n",
    "num_samples = len(y)\n",
    "\n",
    "# Calculate duration in seconds\n",
    "duration = num_samples / sr\n",
    "\n",
    "# Output the sample rate and number of samples\n",
    "print(f\"Sample Rate: {sr} Hz\")\n",
    "print(f\"Number of Samples: {num_samples}\")\n",
    "print(f\"Duration: {duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e6d47-6b26-44c9-8696-18d323237ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default dehavior of librosa.load\n",
    "# load audio files at a sample rate of 22.050 Hz by default unless specified otherwise usign the se parameter\n",
    "\n",
    "# if you want to keep the original sample rate of the audio file , you can set sr=None when loading the audio\n",
    "\n",
    "y, sr = librosa.load('path_to_your_audio_file.wav', sr=None)\n",
    "\n",
    "# example if you have an audio file that is 5 seconds long and is sampled at 22,055 Hz the total number of samples would be\n",
    "# total samples = 22.050 ssamples / second *  5 seconds = 110,250 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5a690-c340-493b-a4f0-3a819b43a16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a9ced-d04f-4f1f-89b5-f8a5eda7349f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d5919-f5d2-45a6-a126-695de9e089e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc9f10-3952-47e8-b3d5-e1e0fb0e5c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69c743-9145-4607-b123-8abf6693398e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e949e-7202-41c9-8605-0ba9ecc78e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SER)",
   "language": "python",
   "name": "ser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
